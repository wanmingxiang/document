# RedShift 

## 关键技术点

1. 自动表优化（Automatic Table Optimization，ATO）：Redshift通过分析集群工作负载，生成分布和排序键的推荐，并提供工具来无缝应用这些推荐。ATO定期收集查询执行元数据，生成推荐，并估计每个推荐的预期收益。Redshift提供了手动和自动两种方式来应用这些推荐。

2. 自动工作负载管理（Automatic Workload Management，AutoWLM）：Redshift根据工作负载特征动态选择查询并发性和内存分配，以平衡排队查询的延迟和执行中查询的资源利用率。
3. 自动化维护和运维：Redshift通过自动化维护任务（如vacuum、analyze和刷新物化视图）和基于机器学习的自主功能，减轻了用户对集群的维护和性能调优的负担。Redshift还监控和分析用户工作负载，识别性能改进的机会，并自动应用分布和排序键的推荐。
4. 并发扩展和计算隔离：Redshift通过弹性调整和并发扩展功能，使用户能够根据实际需求快速增加或减少计算节点。并发扩展功能可以动态扩展集群，以处理更多的并发查询。此外，Redshift还支持计算隔离，允许用户在不同的Redshift计算集群和AWS账户之间安全共享数据。 
5. 自动化视图维护和查询重写：Redshift支持自动化的物化视图维护和查询重写。它可以自动检测过时的物化视图，并根据视图在查询工作负载中的效用和刷新成本的优先级进行维护。Redshift还可以自动重写查询，以使用最佳的物化视图来优化查询性能。



### elastic resize

在集群大小扩展方面，Redshift提供了弹性调整（Elastic Resize）功能，允许用户根据当前的计算需求快速添加或删除计算节点。弹性调整是一种轻量级的元数据操作，不需要重新分配底层数据分布。它通过重新组织数据分区分配来实现平衡计算节点上的数据分区数量，并在后台从S3重新加载已移动的数据分区。

### concurrent scaling

在并发扩展方面，Redshift提供了并发扩展（Concurrency Scaling）功能，当用户需要更多并发查询时，它可以动态扩展集群。当分配的计算资源被充分利用并且新的查询开始排队时，Redshift会自动附加额外的并发扩展计算集群，并将排队的查询路由到这些计算集群上。并发扩展计算集群会从RMS重新加载数据。



### ATO 

在上述信息中，提到了Redshift的自动表优化（Automatic Table Optimization）功能。这个功能通过分析集群的工作负载，生成分布和排序键的推荐，并提供工具来无缝应用这些推荐。自动表优化定期收集查询执行的元数据，如优化的查询计划、基数和谓词选择性，以生成推荐。此外，它估计每个推荐的预期收益，并只显示高度有益的推荐。分布键顾问专注于在给定工作负载下最小化总网络分布成本。分布键不能孤立选择，而需要综合考虑参与工作负载的所有表。因此，自动表优化会从工作负载中的所有连接构建加权连接图，然后选择最小化总网络分布成本的分布键。类似地，排序键顾问专注于减少需要从磁盘检索的数据量。根据查询工作负载，自动表优化分析所有范围限制扫描操作的选择性，并推荐可以改善区域映射过滤效果（即数据块修剪）的排序键



### AWM

Redshift还提供了自动工作负载管理（Automatic Workload Management）功能。它根据工作负载特征动态选择查询并分配内存，以实现最佳的并发执行效果。自动工作负载管理的目标是在保证低延迟的同时，充分利用资源并减少排队查询的等待时间。



### 2.3 SIMD矢量化扫描

 Redshift为生成的代码添加了一个SIMD矢量化扫描层，用于访问数据块并评估谓词作为函数调用。与即时编译的其他步骤不同，矢量化扫描函数是预编译的，并覆盖所有数据类型及其支持的编码和压缩方案。该层的输出将符合谓词条件的元组的列值存储在堆栈上的本地数组中，供下游步骤访问。除了由于SIMD而导致的更快的扫描代码外，这还减少了寄存器压力和必须编译的内联代码量，从而使某些查询在宽表上的编译速度提高数个数量级。设计将列按照一块元组的方式在扫描步骤中执行，并在连接和聚合步骤中按照一块元组的方式执行。在代码生成过程中，根据访问的列的总宽度和线程专用（L2）CPU缓存的大小动态确定以列为单位进行处理的块的大小



### 2.8 自适应执行 

Redshift的执行引擎根据运行时的统计信息，通过在生成的代码或运行时属性上进行动态优化来提升性能。例如，Redshift中布隆过滤器（BF）的实现展示了动态优化的重要性。当复杂查询连接大型表时，可能会在计算节点上传输大量数据进行连接处理，或者由于内存有限而将数据溢出到磁盘。这可能导致网络和/或I/O瓶颈，影响查询性能。Redshift使用布隆过滤器来提高此类连接的性能。布隆过滤器可以高效地在源端过滤不匹配连接关系的行，减少在网络上传输或溢出到磁盘的数据量。在运行时，连接操作根据已处理的确切数据量决定将用于构建布隆过滤器的内存量。例如，如果连接将数据溢出到磁盘，则连接操作可以决定构建更大的布隆过滤器以实现更低的误报率。这个决策增加了布隆过滤器的剪枝能力，并可能减少探测阶段的溢出。类似地，引擎在运行时监视每个布隆过滤器的有效性，并在拒绝比例较低时禁用它，因为过滤器会影响性能。执行引擎可以定期重新启用布隆过滤器，因为数据的时间模式可能使先前无效的过滤器变得有效。



### 2.9 AQUA 

for Amazon Redshift Amazon Redshift的高级查询加速器（AQUA）是一个多租户服务，它充当Redshift Managed Storage的离线缓存层，并为复杂的扫描和聚合操作提供推送加速。AQUA在本地SSD上缓存热数据，避免了从像Amazon S3这样的区域服务中拉取数据的延迟，并减少了在Redshift计算节点中填充缓存存储的需求。为了避免引入网络瓶颈，该服务提供了一个功能接口，而不是存储接口。Redshift识别适用的扫描和聚合操作，并将它们推送到AQUA进行处理，并返回结果。实质上，AQUA是一个在数据中心规模上进行计算存储的解决方案。通过采用多租户架构，AQUA有效地利用了昂贵的资源，如SSD，并提供了一个缓存服务，不受集群转换（如调整大小和暂停-恢复）的影响。为了使AQUA尽可能快速，我们设计了定制的服务器，利用AWS的Nitro ASIC进行硬件加速的压缩和加密，并利用FPGA进行高吞吐量的过滤和聚合操作执行。FPGA并非按查询基础进行编程，而是用于实现包含数据库类型和操作的自定义多核VLIW处理器，其中包含了流水线化的基本操作。服务中的每个节点都有一个编译器，将操作映射到本地CPU或加速器上。通过这样做，可以显著加速可以在FPGA上高效执行的复杂操作。



### 5.3 查询预测框架 

Redshift的查询预测框架是基于机器学习模型来预测查询的内存消耗和执行时间。该框架在每个Redshift集群内运行，收集训练数据，训练一个XGBOOST模型，并在需要时进行推断。这使得Redshift能够从工作负载中学习并自我调整以提高性能。将预测器放在集群本身上有助于快速应对不断变化的工作负载，如果模型在集群外进行训练并且仅在集群上用于推断，这是不可能的。代码编译子系统也利用查询预测框架，在优化和调试编译之间进行选择，提高整体查询响应时间。



# Idea

1， 存算分离架构

2， 当数据库中的内容达到阈值后，起后台任务， 按聚类转换数据；并重新分布；

3， 当数据转换完成后， 切元数据

4， 设计不断业务的方案

4， 方案的缺陷是空间利用率的问题；



自适应索引框架







